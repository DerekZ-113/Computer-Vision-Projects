# Computer Vision Projects - CS5330 2024 Fall

## Table of Contents

- [Computer Vision Projects - CS5330 2024 Fall](#computer-vision-projects---cs5330-2024-fall)
  - [Table of Contents](#table-of-contents)
  - [Project Overview](#project-overview)
  - [Autonomous Vehicle Vision Pipeline](#autonomous-vehicle-vision-pipeline)
  - [Technologies Used](#technologies-used)
  - [Detailed Project Descriptions](#detailed-project-descriptions)
    - [01 Lane Detection for Autonomous Vehicles](#01-lane-detection-for-autonomous-vehicles)
    - [02 Traffic Sign Detection for Autonomous Vehicles](#02-traffic-sign-detection-for-autonomous-vehicles)
    - [03 Road Segmentation for Autonomous Vehicles](#03-road-segmentation-for-autonomous-vehicles)
    - [04 Object Tracking for Autonomous Vehicles](#04-object-tracking-for-autonomous-vehicles)
  - [General Setup Instructions](#general-setup-instructions)

## Project Overview

This repository showcases a comprehensive **autonomous vehicle computer vision system** developed as part of our coursework for CS5330 Computer Vision, Fall Semester 2024. Our four interconnected projects collectively address the core visual perception challenges that **self-driving cars** must solve to navigate safely and effectively in real-world environments.

Each project tackles a fundamental aspect of **autonomous driving perception**:

üõ£Ô∏è **Lane Detection** - Enables vehicles to maintain lane position and follow road geometry for safe navigation  
üö¶ **Traffic Sign Recognition** - Allows vehicles to understand and comply with traffic regulations and intersection management  
üõ§Ô∏è **Road Segmentation** - Helps vehicles distinguish drivable areas from obstacles and identify safe navigation zones  
üëÅÔ∏è **Object Tracking** - Enables vehicles to monitor and predict the movement of dynamic objects like pedestrians and other vehicles  

Together, these projects form a **cohesive autonomous vehicle vision system** that demonstrates how multiple computer vision techniques work in harmony to create the visual intelligence required for safe autonomous navigation. Each component is essential for automotive safety, as self-driving vehicles must simultaneously understand road structure, follow traffic rules, identify safe driving areas, and track moving objects in their environment.

## Autonomous Vehicle Vision Pipeline

Our projects simulate the key components of a **production autonomous vehicle's perception system**:

```
üé• Automotive Camera Input
    ‚Üì
üõ£Ô∏è Lane Detection (Navigation & Steering Control)
    ‚Üí Real-time lane boundary identification with RANSAC outlier removal
    ‚Üí Temporal smoothing for steering stability (30-frame buffering)
    ‚Üí Automotive-grade HSV color filtering for robust lane marking detection
    ‚Üì
üö¶ Traffic Sign Detection (Regulatory Compliance & Safety)
    ‚Üí YOLOv5-based stop sign and traffic light recognition (90% daytime accuracy)
    ‚Üí Real-time automotive-grade confidence thresholding (0.4 threshold)
    ‚Üí 24/7 operation with nighttime optimization (60% accuracy)
    ‚Üì
üõ§Ô∏è Road Segmentation (Environment Understanding & Path Planning)
    ‚Üí Custom U-Net architecture for pixel-level road identification (94.94% accuracy)
    ‚Üí Real-time drivable area detection for autonomous navigation
    ‚Üí Automotive-optimized 256x256 resolution for edge computing platforms
    ‚Üì
üë• Object Tracking (Dynamic Scene Analysis & Collision Avoidance)
    ‚Üí YOLOv8 + Lucas-Kanade optical flow for multi-object tracking
    ‚Üí Specialized pedestrian and vehicle tracking for safety-critical scenarios
    ‚Üí Real-time trajectory prediction for autonomous vehicle decision-making
    ‚Üì
üöó Autonomous Vehicle Decision & Control System
```

This **integrated automotive perception pipeline** mirrors how real autonomous vehicles process visual information, where each component provides critical data that informs the vehicle's understanding of its environment and influences driving decisions in real-time.

## Technologies Used

- **Autonomous Vehicle Deep Learning**: TensorFlow, PyTorch, Ultralytics YOLOv5/YOLOv8
- **Automotive Computer Vision**: OpenCV, NumPy, SciPy optimized for real-time processing
- **Safety-Critical Algorithms**: Custom U-Net, RANSAC, Lucas-Kanade Optical Flow
- **Automotive Image Processing**: Canny edge detection, Hough Transform, HSV color filtering
- **Real-time Visualization**: Matplotlib, automotive-grade video processing at 20 FPS

## Detailed Project Descriptions

### 01 Lane Detection for Autonomous Vehicles

**Real-time lane boundary detection system for autonomous vehicle navigation**

**Autonomous Vehicle Features:**
- **Steering Control Support**: Provides lane center information for automated vehicle control
- **Safety Systems**: Lane departure detection with immediate alert capabilities
- **Path Planning Integration**: Accurate road geometry data for autonomous navigation algorithms
- **Real-time Performance**: 20 FPS processing suitable for automotive safety requirements

**Key Automotive Technologies:**
- **HSV Color Filtering**: Range [0,0,220] to [180,25,255] for robust white lane detection
- **RANSAC Algorithm**: 10-pixel distance threshold with 100 iterations for automotive-grade outlier removal
- **Temporal Smoothing**: 30-frame deque buffering system for steering stability
- **Automotive Vision**: Trapezoidal region of interest optimized for vehicle-mounted cameras

**Setup for Autonomous Vehicle Development:**
```bash
pip install opencv-python numpy
python WebCamSave.py -f video_file_name -o out_video.avi
```

**Autonomous Vehicle Controls:**
- Press `s` to Pause/Resume (debugging autonomous algorithms)
- Press `q` to Quit application

**Demo Videos:** [Google Drive - Autonomous Vehicle Testing](https://drive.google.com/drive/folders/1MfBh7xroQ3lGHEUabCWor48rcw4rfypk?usp=drive_link)

---

### 02 Traffic Sign Detection for Autonomous Vehicles

**Safety-critical traffic sign recognition system using fine-tuned YOLOv5**

**Autonomous Vehicle Features:**
- **Regulatory Compliance**: Automatic stop sign and traffic light detection for intersection safety
- **24/7 Operation**: Optimized for both daytime (90% accuracy) and nighttime (60% accuracy) autonomous driving
- **Real-time Decision Support**: Automotive-grade confidence thresholding for immediate response
- **Safety Integration**: Emergency braking triggers and intersection management support

**Model Performance for Autonomous Vehicles:**
- **Daytime Accuracy**: 90% (meets automotive safety standards)
- **Nighttime Accuracy**: 60% (enhanced with specialized low-light training)
- **Processing Speed**: Real-time inference suitable for autonomous vehicle control loops
- **Confidence Thresholding**: 0.4 threshold optimized for automotive safety applications

**Setup for Autonomous Vehicle Development (Google Colab):**
```bash
!git clone https://github.com/ultralytics/yolov5
%cd yolov5
!pip install -r requirements.txt
python3 train.py --img 640 --batch 16 --epochs 50 --data '/content/data.yaml' --weights yolov5s.pt
python3 WebCamSave.py -f test_video.mp4 -o autonomous_output.avi
```

**Autonomous Vehicle Model Downloads:**
- [Base Automotive Model](https://drive.google.com/file/d/1BBV0IBQMYGVgzXych-46r6Pmu3uuWLtb/view?usp=sharing) - 90% daytime accuracy
- [Enhanced Nighttime Model](https://drive.google.com/file/d/1ny4jpXZBfa-oN0bZNR4hRDi9sVtU-3Gu/view?usp=sharing) - 24/7 operation

**Demo Videos:** [Google Drive - Autonomous Vehicle Testing](https://drive.google.com/drive/folders/1eZgsuifq_x8-8hUAbe8NKM1LbDlg1hna?usp=drive_link)

---

### 03 Road Segmentation for Autonomous Vehicles

**Pixel-level road segmentation using custom U-Net for autonomous navigation**

**Autonomous Vehicle Features:**
- **Drivable Area Detection**: Precise identification of safe navigation zones vs. obstacles
- **Path Planning Support**: Detailed road geometry for autonomous vehicle trajectory planning
- **Real-time Processing**: 94.94% accuracy suitable for safety-critical automotive applications
- **Urban Environment Handling**: Optimized for complex city driving scenarios

**Model Architecture for Automotive Applications:**
- **Input Resolution**: 256x256x3 optimized for automotive edge computing platforms
- **Training Accuracy**: 94.94% meeting automotive safety thresholds
- **Validation Accuracy**: 93.03% ensuring robust real-world performance
- **IoU Metrics**: 86.98% training, 81.49% validation for geometric precision

**Setup for Autonomous Vehicle Development:**
```bash
pip install tensorflow opencv-python-headless numpy matplotlib scikit-learn
```

**Automotive Dataset:** [Cityscapes Urban Driving Dataset](https://drive.google.com/drive/folders/1qRVz70ixvsj76Pp2Gwv982A6ZFzYPG-o) (1,391 images)

**Training Files for Autonomous Vehicles:** Available in [Google Drive](https://drive.google.com/drive/folders/1qRVz70ixvsj76Pp2Gwv982A6ZFzYPG-o)

---

### 04 Object Tracking for Autonomous Vehicles

**Real-time multi-object tracking system for autonomous vehicle safety**

**Autonomous Vehicle Features:**
- **Collision Avoidance**: Real-time tracking of pedestrians, vehicles, and obstacles
- **Trajectory Prediction**: Movement pattern analysis for autonomous vehicle decision-making
- **Safety-Critical Monitoring**: Specialized tracking of people and vehicles in the vehicle's path
- **Multi-Object Capability**: Simultaneous tracking of multiple dynamic objects

**Technical Implementation for Automotive Applications:**
- **Detection Model**: YOLOv8 optimized for automotive environments
- **Tracking Algorithm**: Lucas-Kanade optical flow with automotive parameters
- **Performance Optimization**: 640x480 resolution, detection every 3 frames for real-time performance
- **Safety Features**: Configurable target classes, emergency controls for testing

**Interactive Controls for Autonomous Vehicle Development:**
- Press `t` to toggle tracking on/off (essential for automotive testing scenarios)
- Press `c` to clear tracking data and trajectories (useful for scenario testing)
- Press `q` to emergency quit for autonomous vehicle safety testing

**Setup for Autonomous Vehicle Development:**
```bash
pip install ultralytics opencv-python scipy numpy
python3 webcam.py
```

**Automotive Configuration:**
```python
classes_to_track = ['person']  # Configurable for autonomous vehicle priorities
detection_interval = 3  # Every 3 frames for automotive efficiency
```

**Demo Videos:** [Google Drive - Autonomous Vehicle Testing](https://drive.google.com/drive/folders/10ehLSJHL3uk9QPhVTZnkJCsxqea7fR6Z?usp=share_link)

## General Setup Instructions

**Autonomous Vehicle Development Requirements:**
- Python 3.6 or higher (automotive compatibility standards)
- OpenCV 4.x (optimized for real-time automotive processing)
- NumPy, SciPy, Matplotlib (automotive-grade numerical computing)
- TensorFlow (for U-Net road segmentation)
- Ultralytics (for YOLOv5/YOLOv8 automotive models)

**Common Dependencies for Autonomous Vehicle Development:**
```bash
pip install opencv-python numpy scipy matplotlib tensorflow ultralytics
```

**Automotive Hardware Recommendations:**
- GPU with CUDA support (essential for real-time autonomous vehicle processing)
- Minimum 8GB RAM (automotive computing requirements)
- Automotive cameras or dashcam footage for testing